---
title: "Different Models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Quadratic Model 

```{r}
## Simulating Data from a Regression Model
  ## This R-chunk is meant to be played in your R Console.
  ## It allows you to explore how the various elements
  ## of the regression model combine together to "create"
  ## data and then use the data to "re-create" the line.

  set.seed(101) #Allows us to always get the same "random" sample
                #Change to a new number to get a new sample

  n <- 30 #set the sample size

  X_i <- runif(n, -2, 4) 
    #Gives n random values from a uniform distribution between 15 to 45.

  beta0 <- -3.2 #Our choice for the y-intercept. 

  beta1 <- 4.2 #Our choice for the slope. 
  beta2 <- -1.1

  sigma <- 0.5 #Our choice for the std. deviation of the error terms.


  epsilon_i <- rnorm(n, 0, sigma) 
    #Gives n random values from a normal distribution with mean = 0, st. dev. = sigma.

  Y_i <- beta0 + beta1*X_i + beta2 * X_i^2 + epsilon_i 
    #Create Y using the normal error regression model

  fabData <- data.frame(y=Y_i, x=X_i) 
    #Store the data as data

  #View(fabData) 
  

  #In the real world, we begin with data (like fabData) and try to recover the model that 
  # (we assume) was used to created it.

  fab.lm <- lm(y ~ x + I(x^2), data=fabData) #Fit an estimated regression model to the fabData.

  b <- coef(fab.lm)
  summary(fab.lm) #Summarize your model. 

  plot(y ~ x, data=fabData) #Plot the data.

  curve(b[1] + b[2] * x + b[3] * x^2, add = TRUE) #Add the estimated regression line to your plot.


  # Now for something you can't do in real life... but since we created the data...

  curve(beta0+beta1*x+beta2*x^2, lty=2, add = TRUE) 
    #Add the true regression line to your plot using a dashed line (lty=2). 

  legend("topleft", legend=c("True Line", "Estimated Line"), lty=c(2,1), bty="n") 
    #Add a legend to your plot specifying which line is which.
```
## Cubic Model

```{r}
## Simulating Data from a Regression Model
  ## This R-chunk is meant to be played in your R Console.
  ## It allows you to explore how the various elements
  ## of the regression model combine together to "create"
  ## data and then use the data to "re-create" the line.

  set.seed(101) #Allows us to always get the same "random" sample
                #Change to a new number to get a new sample

  n <- 30 #set the sample size

  X_i <- runif(n, -1, 3) 
    #Gives n random values from a uniform distribution between 15 to 45.

  beta0 <- 2.5 #Our choice for the y-intercept. 

  beta1 <- -1.5 #Our choice for the slope. 
  beta2 <- -2.5
  beta3 <- 0.8

  sigma <- 0.5 #Our choice for the std. deviation of the error terms.


  epsilon_i <- rnorm(n, 0, sigma) 
    #Gives n random values from a normal distribution with mean = 0, st. dev. = sigma.

  Y_i <- beta0 + beta1*X_i + beta2 * X_i^2 + beta3 * X_i^3 + epsilon_i 
    #Create Y using the normal error regression model

  fabData <- data.frame(y=Y_i, x=X_i) 
    #Store the data as data

  #View(fabData) 
  

  #In the real world, we begin with data (like fabData) and try to recover the model that 
  # (we assume) was used to created it.

  fab.lm <- lm(y ~ x + I(x^2) + I(x^3), data=fabData) #Fit an estimated regression model to the fabData.

  b <- coef(fab.lm)
  summary(fab.lm) #Summarize your model. 

  plot(y ~ x, data=fabData) #Plot the data.

  curve(b[1] + b[2] * x + b[3] * x^2 + b[4] * x^3, add = TRUE) #Add the estimated regression line to your plot.


  # Now for something you can't do in real life... but since we created the data...

  curve(beta0+beta1*x+beta2*x^2+beta3*x^3, lty=2, add = TRUE) 
    #Add the true regression line to your plot using a dashed line (lty=2). 

  legend("topleft", legend=c("True Line", "Estimated Line"), lty=c(2,1), bty="n") 
    #Add a legend to your plot specifying which line is which.
```

## Two Line Model

```{r}
## Simulating Data from a Regression Model
  ## This R-chunk is meant to be played in your R Console.
  ## It allows you to explore how the various elements
  ## of the regression model combine together to "create"
  ## data and then use the data to "re-create" the line.

  set.seed(101) #Allows us to always get the same "random" sample
                #Change to a new number to get a new sample

  n <- 30 #set the sample size
  
  X1_i <- runif(n, 30, 45) 
  X2_i <- sample(c(0,1), n , replace = TRUE)
    #Gives n random values from a uniform distribution between 15 to 45.

  beta0 <- 5 #Our choice for the y-intercept. 
  beta1 <- 1.4 #Our choice for the slope. 
  beta2 <- 30 #Change in intercept
  beta3 <- -1.6 # Change in slope

  sigma <- 1 #Our choice for the std. deviation of the error terms.

  epsilon_i <- rnorm(n, 0, sigma) 
    #Gives n random values from a normal distribution with mean = 0, st. dev. = sigma.

  fabData <- data.frame(y=Y_i, x1=X_i, x2 = X2_i) 
  
  Y_i <- beta0 + beta1*fabData$x1 + beta2 * fabData$x2 + beta3 * fabData$x1 * fabData$x2 + epsilon_i 

  fab.lm <- lm(y ~ x1 + x2 + x1:x2, data=fabData) #Fit an estimated regression model to the fabData.

  b <- coef(fab.lm)
  summary(fab.lm) #Summarize your model. 

  plot(y ~ x1, col = as.factor(x2), data=fabData) #Plot the data.

  curve(b[1] + b[2]*x, add = TRUE) #Add the estimated regression line to your plot.
  
  curve(b[1] + b[2]*x + b[3] + b[4]*x, add = TRUE)


  # Now for something you can't do in real life... but since we created the data...

  curve(beta0+beta1*x+beta2*x2+beta3*x*x2, lty=2, add = TRUE) 
    #Add the true regression line to your plot using a dashed line (lty=2). 

  #legend("topleft", legend=c("True Line", "Estimated Line"), lty=c(2,1), bty="n") 
```